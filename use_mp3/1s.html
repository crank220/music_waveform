<!DOCTYPE html>
<html lang="en">

<head></head>

<body>
  <canvas width="1024" height="256" id="canvas"></canvas>
  <div class="oo"></div>
  <audio src="../mp3/i1.mp3"></audio>
  <button id="play">play</button>
  <style>
    html,
    body {
      height: 100%;
      margin: 0;
    }

    body {
      display: flex;
      justify-content: center;
      align-items: center;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
      z-index: 10;
      width: 1024px;
      height: 256px;
      background: #3c3c3c;
    }

    .oo {
      position: absolute;
      top: 0;
      left: 0;
      z-index: 12;
      width: 1024px;
      height: 256px;
      background-color: hsla(0, 0%, 100%, .6);
    }

    #play {
      position: absolute;
      top: 0;
      right: 0;
      width: 50px;
      height: 20px;
    }
  </style>
  <script>
    // create environment -- audio context
    // define variables
    window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame || window.msRequestAnimationFrame;

    var AudioContext = window.AudioContext || window.webkitAudioContext;
    var audioCtx;
    var source;
    var Animationst;
    try {
      audioCtx = new AudioContext();
      // console.log(audioCtx)
    } catch (e) {
      alert('Your browser does not support AudioContext!');
      console.log(e);
    }

    // use XHR to load an audio track, and
    // decodeAudioData to decode it and stick it in a buffer.
    // Then we put the buffer into the source

    var getData = function () {
      // create audio node to play the audio in the buffer
      source = audioCtx.createBufferSource();
      // console.log(source)

      // 请求
      var request = new XMLHttpRequest();

      //初始化 HTTP 请求参数, 配置请求类型，文件路径等
      request.open('GET', '../mp3/i1.mp3', true);

      // 配置数据返回类型,从服务器取回二进制数据
      request.responseType = 'arraybuffer';

      // 获取完成，对音频进一步操作，解码
      request.onload = function () {
        var audioData = request.response;
        audioCtx.decodeAudioData(audioData, function (buffer) {
          source.buffer = buffer;

          console.log(source.buffer.duration)
          window.audioDuration = source.buffer.duration; //音乐总时长


          source.connect(audioCtx.destination);
          // source.loop = true;
          // console.info(source,source.frequencyBinCount);
        },
          function (e) { console.log("Error with decoding audio data" + e.err); });
      };

      // 发送一个 HTTP 请求
      request.send();
      var number = 0;
      //创建分析器
      var analyser = audioCtx.createAnalyser();
      source = audioCtx.createBufferSource();
      // analyser.minDecibels = -90;
      // analyser.maxDecibels = -10;
      analyser.fftSize = 32;


      console.info(source, analyser)
      //将source与分析器链接
      source.connect(analyser);
      //将分析器与destination链接，这样才能形成到达扬声器的通路
      analyser.connect(audioCtx.destination);

      // console.info(source,audioCtx.destination)


      //开始绘制频谱图
      var canvas = document.getElementById('canvas'),
        cwidth = canvas.width,
        cheight = canvas.height,
        meterWidth = 2,
        gap = 2,
        meterNum = 2048 / 4,
        step = 1,
        capYPositionArray = [];
      var ctx = canvas.getContext('2d');
      //定义一个渐变样式用于画图
      var gradient = ctx.createLinearGradient(0, 0, 1024, 0);
      gradient.addColorStop(1, '#0f0');
      gradient.addColorStop(0.5, '#ff0');
      gradient.addColorStop(0, '#f00');
      ctx.fillStyle = gradient;
      //绘制频谱图
      function drawSpectrum() {
        var array = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(array);
        //清理画布
        // ctx.clearRect(0, 0, cwidth, cheight);
        //只绘制出当前宽度内的线
        // 从频率分布数据中可以看到数组中大于800的数据都是0 
        // console.log(analyser);
        // console.info(audioCtx.destination, array[array.length/2]);

        number++;

        // console.info(window.audioDuration/meterNum*step,audioCtx.currentTime);

        if (window.audioDuration / meterNum * step < audioCtx.currentTime) {
          step++;

          // console.log('第' + (step-1) + '步');
          // console.info(window.audioDuration/meterNum*step,audioCtx.currentTime);

          // console.log(array);
          var value = array[array.length / 2];
          // var value = array[0];
          ctx.fillRect(2 * step, cheight - value, 1, cheight);
          capYPositionArray.push(value);
          // console.log(capYPositionArray);
        }
        // ctx.fillRect(2 * number, cheight - value, 1, cheight);

        Animationst = window.requestAnimationFrame(drawSpectrum);

        if (audioCtx.currentTime > window.audioDuration) {
          cancelAnimationFrame(Animationst);
        }
      }
      Animationst = window.requestAnimationFrame(drawSpectrum);
    };

    getData();
    source.start(0);
      // source.stop();

      // var au = document.querySelector('audio');
      // // document.getElementById('play').addEventListener('click', function(){
      //   // console.log(au.play);
      //   if (au.pause) {
      //     // 暂停中
      //     document.getElementById('play').onclick=function(){
      //     console.log('pause');
      //     au.play();
      //     }
      //   } else {
      //     // 播放中
      //     document.getElementById('play').onclick=function(){

      //     console.log('play');
      //     au.pause();
      //     }
      //   }
      // au.addEventListener('playing', function(){
      //   console.info(au.currentTime,au.duration);
      // })


      // function start() {
      //   startTime = context.currentTime;
      //   var source = context.createBufferSource();
      //   source.buffer = buffer;
      //   source.loop = true;
      //   source.connect(context.destination);
      //   source.start(0, startOffset % buffer.duration);
      // }
  </script>

</body>

</html>